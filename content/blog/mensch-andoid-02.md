+++
author = "Larissa"
categories = ["Thoughts"]
tags = ["spring2019", "artificial-intelligence", "guest-article", "ai-thesis", "german-only"]
date = "2019-03-17"
description = "Teil 02: Bewusstsein - guest article"
featured = "future.jpg"
featuredpath = "date"
linktitle = ""
title = "Mensch-Android - wo sind die Unterschiede? 02"
type = "post"
+++

## guest article from [luanasschreibstube.wordpress.com](https://luanasschreibstube.wordpress.com)

Manche bezeichnen das Bewusstsein als letzten Unterschied zwischen Mensch und Maschine, beziehungsweise zwischen stumpfer Maschine und künstlicher Intelligenz. Vielleicht ist das Bewusstsein ja auch die Seele, die uns als Lebewesen, als Mensch ausmacht?

# Kann eine Maschine ein Bewusstsein entwickeln?

Gehen wir zunächst von einer körperlosen Maschine aus. Sie ist ein Programm, eingebettet in ein System von Aktion und Reaktion, das Daten (in Nullen und Einsen), also elektrische Impulse verwaltet. Selbst wenn die Maschine Zugang zu Video-Kameras, Mikrofonen, Sensoren hätte, mit denen sie theoretisch die Außenwelt wahrnehmen könnte, so hätte sie dennoch keine physischen Teile, um mit der Außenwelt zu interagieren. Auch wenn sie über Text/Sprache direkt mit Menschen kommunizieren würde, kommen bei ihr nur Daten an. Für die Maschine ist es nur eine Reaktion auf eine Impulsabfolge. Es gibt nichts, das für sie erfahrbar ist, das außerhalb ihres "Selbst" liegt. Wenn es keine Trennung zwischen "Ich" und "nicht-Ich" gibt, kann sie dann überhaupt ein Selbst-Bewusstsein entwickeln? 

# Bei Maschinen mit Körpern könnte das etwas anderes sein.

Sie sehen, dass es Dinge gibt, die sie nicht beeinflussen, auf die sie nicht zugreifen können. Auch wenn sie intern ebenfalls nur Daten umrechnen, sie erkennen vielleicht, dass bestimmte Daten von ihnen manipulierbar sind (ein Arm auf einem Video, eine Kopfdrehung), während andere Dinge statisch bleiben oder sich ohne ihr Zutun verändern. Es muss also Dinge geben, die unabhängig von den Maschinen selbst sind, ergo muss es ein "außen" geben, das nicht "selbst" ist. Der erste Schritt zum "Bewusstsein" wäre getan. 

# Dennoch. "Bewusstsein", wo ist das?

Selbst bei einem bewussten Code können wir in das Programm schauen und sehen nicht mehr als vorher. Ein paar Zahlen haben sich vielleicht verändert, Gewichtungen bestimmter Knoten im Neuronalen Netz, aber es ist (vermutlich) noch immer "unser" Code. Wie also gehen wir sicher, dass da ein Bewusstsein ist? Wer von euch hat letzte Woche "Ghost in a Shell" gesehen? Dort ist das "Bewusstsein" auch nur Code, bestimmte Erinnerungen können einfach rausgelöscht werden. Was ist es dann noch mehr als ein Computerprogramm? Wenn man es neu installieren würde, wäre das Bewusstsein noch da? Damien aus "The Kingdom of the Blind" von Maureen McHugh denkt ja: "Its consciousness is in the code. Its code and body are unchanged. If someone has a heart attack and you shock them back, they come back as themselves. Your body is you. DMS’s software and hardware is DMS." (DMS ist die KI in diesem Fall.) (aus [http://www.lightspeedmagazine.com/fiction/the-kingdom-of-the-blind/](http://www.lightspeedmagazine.com/fiction/the-kingdom-of-the-blind/))

# Aber: Ist unser menschliches Bewusstsein mehr als ein paar elektronische Nachrichten im Gehirn?

Oder wie Hans Moravec schreibt: "Auch ein Gehirn offenbart unter dem Mikroskop des Neurobiologen nicht die Intelligenz, die es in einem leibhaftigen Gespräch beweist." (Computer übernehmen die Macht, S.111) Nicht zuletzt ist die Frage nach dem Ort der Seele, des "Selbst", zumindest für die Wissenschaft noch unbeantwortet. 

# Wie finden wir heraus, ob sich eine Maschine bewusst ist?

Für den unwahrscheinlichen Fall, das eine körperlose Maschine ein Bewusstsein entwickelt - wie könnten wir mit ihr kommunizieren? In der eben erwähnten Kurzgeschichte "The Kingdom of the Blind" schickt ein Stromversorgungssystem regelmäßige Blackouts durch die Stadt und keiner weiß, wieso. Die Informatiker versuchen mit Zeichenketten, also Sequenzen aus Nullen und Einsen, die so gestaltet sind, dass sie nicht zufällig so entstanden sein können, eine Reaktion vom System zu provozieren...
"She ran the program that sent DMS the string of a thousand 10101s, a thousand times.
Instantly, her printer light blinked. DMS had started the electrical pattern sequence again.
She ran the program again.
DMS started over again.
She ran the program a third time. And a third time her printer hummed. She ran the program a fourth time, thinking, *I’m talking to you. I’m responding to you. Do you know someone else is out here? Or is it like a toddler knocking something off a high chair just to see it fall?* The fourth time, there was no response. DMS didn’t start the sequence that should have started the lights going out at DM Kensington Medical but which would, in actual fact, simply send an alert to Damien and Sydney. DMS had responded three times, and ignored it the fourth. She felt a chill. […] 
DMS was choosing to act or not act. Software didn’t choose. It ran."

Ich weiß nicht, wie es euch geht, aber ich finde das Thema super spannend. **Wie fühlt sich ein Computer eigentlich, wenn er fühlt? Wie sieht er sich selbst? Was meint ihr?**

